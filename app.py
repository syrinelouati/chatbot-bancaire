# -*- coding: utf-8 -*-
"""app
 
Automatically generated by Colab.
 
Original file is located at
https://colab.research.google.com/drive/1IvQJEkZK5BJihvYKio2yqF6RIGTSW0jd
"""
 
# app.py
import os
import json
import base64
import pandas as pd
from langdetect import detect
from sentence_transformers import SentenceTransformer
from sklearn.neighbors import NearestNeighbors
import streamlit as st
from groq import Groq
 
# --- Configuration Streamlit
st.set_page_config(page_title="Chatbot Bancaire + Extraction Invoice", layout="centered")
st.title("üí¨ Chatbot Bancaire")
 
# Initialiser l'historique de chat
if "messages" not in st.session_state:
    st.session_state.messages = []
 
# Charger mod√®le et donn√©es du chatbot (avec cache)
@st.cache_resource
def load_model():
    return SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
 
@st.cache_data
def load_data():
    df = pd.read_csv("cleanedTranslatedBankFAQs.csv", usecols=[
        "Question", "Answer", "Class", "Profile",
        "Profile_fr", "Profile_ar", "Class_fr", "Class_ar",
        "Question_fr", "Question_ar", "Answer_fr", "Answer_ar"
    ])
    return df
 
model = load_model()
df = load_data()
 
@st.cache_resource
def build_embeddings(df):
    embeddings = {
        "fr": model.encode(df["Profile_fr"].fillna('') + " - " + df["Question_fr"].fillna(''), show_progress_bar=True),
        "en": model.encode(df["Profile"].fillna('') + " - " + df["Question"].fillna(''), show_progress_bar=True),
        "ar": model.encode(df["Profile_ar"].fillna('') + " - " + df["Question_ar"].fillna(''), show_progress_bar=True)
    }
    nn_models = {
        lang: NearestNeighbors(n_neighbors=1, metric="cosine").fit(embeddings[lang])
        for lang in embeddings
    }
    return embeddings, nn_models
 
embeddings, nn_models = build_embeddings(df)
 
# Initialiser client Groq (extraction image)
os.environ["GROQ_API_KEY"] = "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"
client = Groq()
 
# Fonctions d'extraction invoice via Groq/LLaMA
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
 
def extract_invoice_data(base64_image):
    system_prompt = """
    You are an OCR-like data extraction tool that extracts hotel invoice data from images.
    1. Please extract the data in this hotel invoice, grouping data according to theme/sub groups, and then output into JSON.
    2. Please keep the keys and values of the JSON in the original language.
    3. The type of data you might encounter in the invoice includes but is not limited to: hotel information, guest information, invoice information,
       room charges, taxes, and total charges etc.
    4. If the page contains no charge data, please output an empty JSON object and don't make up any data.
    5. If there are blank data fields in the invoice, include them as "null" values in the JSON object.
    6. If there are tables in the invoice, capture all rows and columns in the JSON object.
       Even if a column is blank, include it as a key in the JSON object with a null value.
    7. If a row is blank, denote missing fields with "null" values.
    8. Don't interpolate or make up data.
    9. Please maintain the table structure of the charges, i.e. capture all rows and columns in the JSON object.
    """
    response = client.chat.completions.create(
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Extract the data in this hotel invoice and output into JSON."},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}", "detail": "high"}}
                ]
            }
        ],
        temperature=0.0,
    )
    return response.choices[0].message.content
 
# Fonction chatbot multilingue
def generate_answer(user_question):
    try:
        lang = detect(user_question)
    except:
        lang = "fr"
    if lang not in ["fr", "en", "ar"]:
        lang = "fr"
    if lang == "fr":
        questions = df["Profile_fr"].fillna('') + " - " + df["Question_fr"].fillna('')
        answers = df["Answer_fr"]
        profils = df["Profile_fr"]
        intro_template = "üó£Ô∏è En tant que **{}**, tu peux :"
    elif lang == "ar":
        questions = df["Profile_ar"].fillna('') + " - " + df["Question_ar"].fillna('')
        answers = df["Answer_ar"]
        profils = df["Profile_ar"]
        intro_template = "üó£Ô∏è ÿ®ÿµŸÅÿ™ŸÉ **{}**ÿå ŸäŸÖŸÉŸÜŸÉ :"
    else:
        questions = df["Profile"].fillna('') + " - " + df["Question"].fillna('')
        answers = df["Answer"]
        profils = df["Profile"]
        intro_template = "üó£Ô∏è As a **{}**, you can:"
 
    input_embedding = model.encode([user_question])
    nn_model = nn_models[lang]
    _, index = nn_model.kneighbors(input_embedding)
    answer = answers.iloc[index[0][0]]
    profil = profils.iloc[index[0][0]]
    intro = intro_template.format(profil)
    return f"{intro}\n\n{answer}"
 
# ---- Streamlit UI ----
 
# Onglets pour choisir le mode
mode = st.sidebar.selectbox("Choisir le mode :", ["Chatbot Bancaire", "Extraction des virements"])
 
if mode == "Chatbot Bancaire":
    # Afficher l'historique des messages
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
 
    # Saisie utilisateur
    if prompt := st.chat_input("Posez votre question..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
 
        response = generate_answer(prompt)
        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)
 
elif mode == "Extraction des virements":
    st.write("üì§ Upload une image de facture (PNG, JPG) √† analyser.")
    uploaded_file = st.file_uploader("Choisissez une image...", type=["png", "jpg", "jpeg"])
    if uploaded_file is not None:
        # Sauvegarder temporairement le fichier upload√©
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
 
        st.image(uploaded_file, caption="Image upload√©e", use_column_width=True)
        if st.button("Extraire les donn√©es"):
            with st.spinner("Extraction en cours..."):
                base64_img = encode_image(temp_path)
                try:
                    json_data = extract_invoice_data(base64_img)
                    st.json(json.loads(json_data))
                except Exception as e:
                    st.error(f"Erreur lors de l'extraction : {e}")
            os.remove(temp_path)
